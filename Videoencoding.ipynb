{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearningLab_BasicEncoding_v5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mEUPFEj94m0A",
        "w6xVZ_qrgC1P",
        "GAS_K2t7O-Gl",
        "8DuIDmyQbwFe",
        "DwiNlFdavE8U",
        "Duv8gDzTkKjP",
        "566nb3rYg3a5",
        "NmhW67mgekFf",
        "pHgbv5iWGVH6",
        "8kkF7JoaS_P2",
        "z2_Rml-OoC16",
        "FE28ufzGoj8Z",
        "-9sPhvxcoqTn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEUPFEj94m0A"
      },
      "source": [
        "# Tutorial - A Basic Encoding Script (in Python)\n",
        "\n",
        "In this tutorial, you will learn how to create an encoding from scratch, using the Bitmovin APIs and the Python SDK that wraps them. We will explain the concepts and the terminology that we use as we go along.\n",
        "\n",
        "This tutorial concentrates on a typical use case: \n",
        "- taking a **single source file** that contains both audio and video.\n",
        "- encoding it into a **fixed ladder** of multiple video representations (*sometimes called renditions*) at different resolutions and bitrates, and separate audio representations.\n",
        "- generating **manifests** that can be played back by any modern ABR video player on most devices and browsers.\n",
        "\n",
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/ABR_basics.png\" align=\"right\" width=\"500px\">\n",
        "\n",
        "\n",
        "This type of manifest-based output is common in **Adaptive Bitrate Streaming** (ABR) use cases, such as used in OTT applications. With this streaming format, the video player can choose which representation to play, based on its available bandwidth and capabilities, and can also switch between them dynamically, going to a higher bitrate (and therefore better quality) as the available bandwidth increases, or going to lower bitrates (and lower qualities) as the network conditions deteriorate. \n",
        "\n",
        "> üìö &nbsp; *See https://bitmovin.com/adaptive-streaming for more.*\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6xVZ_qrgC1P"
      },
      "source": [
        "##### <font color=\"gray\">***How to use this tutorial***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmsGYQxygvEC"
      },
      "source": [
        "<font color=\"gray\">This Colab interactive tool allows you to run Python code interactively. You can execute individual parts of the script, modify them and re-run them easily. Note however that once you get to the part of the code that actually creates resources through the Bitmovin API, re-running code may have undesired side-effects.\n",
        "\n",
        "<font color=\"gray\">We've interspersed code with explanations about each step taken. You will also find additional pointers, marked with the following icons:\n",
        "\n",
        "- <font color=\"gray\">üóí &nbsp; for general information\n",
        "- <font color=\"gray\">üìö &nbsp; for links to documentation\n",
        "- <font color=\"gray\">üí° &nbsp; for tips\n",
        "- <font color=\"gray\">‚≠êÔ∏è &nbsp; for information on best practices\n",
        "- <font color=\"gray\">üîé &nbsp; for pointers to related but more advanced topics\n",
        "</font>\n",
        "\n",
        "<font color=\"gray\"> Note that the code in this tutorial does not pretend to provide an example of who to write good or efficient Python. We abuse the flexibility of the language for the purpose of making this example as readable as possible even by those unfamiliar with Python. The focus is on explaining the Bitmovin APIs, not Python..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAS_K2t7O-Gl"
      },
      "source": [
        "# Understanding the API model\n",
        "To configure an encoding with the Bitmovin API (and SDK) requires creating and inter-linking a number of resources (surfaced as objects in the SDK). This diagram provides a high-level view of the most common ones involved in pretty much all encodings.\n",
        "\n",
        "Each of these resources will be explained in the relevant section below.\n",
        "\n",
        "![object model](http://demo.bitmovin.com/public/learning-labs/encoding/ObjectModel_ABR_v3.png)\n",
        "\n",
        "> <font color=\"gray\">üîé &nbsp; For a complete description of the Bitmovin data model, check our [Object model documentation](https://bitmovin.com/docs/encoding/tutorials/understanding-the-bitmovin-encoding-object-model) üìö ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPLhXVwYOXem"
      },
      "source": [
        "# Tutorial Setup\n",
        "\n",
        "For the purpose of this tutorial, we need to first import a few helpers. They are not part of the standard SDK, and are not something you would need in your own scripts, so no need to worry about understanding this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q1eo-B_ntPj"
      },
      "source": [
        "%%capture\n",
        "!rm -rf learning-labs\n",
        "!git clone -b feature/encoding-labs-jupyter-utils https://github.com/bitmovin/learning-labs.git\n",
        "\n",
        "import sys\n",
        "sys.path.append('./learning-labs/encoding/python/lab_nb_utils')\n",
        "import config as cfg\n",
        "import helpers\n",
        "\n",
        "from IPython.display import Markdown, display, IFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuFFycHznPeh"
      },
      "source": [
        "## Secret Sauce\n",
        "\n",
        "We will now create a number of configuration variables that will be used in the main part of the script. When you start writing production-ready scripts, it is likely that you will obtain them from other parts of your workflow system, and pass them to the script in other ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nP3TI5hS9W9"
      },
      "source": [
        "### API Key\n",
        "The API key is what you need to authenticate with the Bitmovin API. You can find it in the dashboard in the [Account section](https://bitmovin.com/dashboard/account).\n",
        "This key is a <font color=\"darkred\">**secret**</font>, and should be treated as such. If someone else gets hold of your key, they can run encodings on your account (or your organisation accounts) and get information about previous ones.\n",
        "\n",
        "**Note**: *If you cannot find your key in the dashboard, you are probably working in the context of another organization. You will need to temporarily switch to your own first to retrieve the key*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "rsOtBeuobwFQ"
      },
      "source": [
        "cfg.API_KEY='42c45b0a-793d-419e-9357-e3ec02aea270' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVoTEcR-T46s"
      },
      "source": [
        "### Organization\n",
        "The Organization ID indicates what Bitmovin account you want to create and process your encodings in. Leave it empty if you are using your own account. \n",
        "\n",
        "If you belong to a [multi-tenant organization](https://bitmovin.com/docs/encoding/tutorials/multi-tenant-how-to-add-additional-users-to-your-account) in which multiple people collaborate within the same account, you need to get the organisation ID from the dashboard in the [Organization section](https://bitmovin.com/dashboard/organization/overview) - after selecting the correct one from the dropdown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "gjQIA84MT9IP"
      },
      "source": [
        "cfg.ORG_ID='6f754aa8-fd27-4102-b539-52f1f9c26818' #@param {type:\"string\"} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxHwL2tqVcjh"
      },
      "source": [
        "### Storage Credentials\n",
        "In this tutorial, we will use an S3 bucket to store the output of the encoding. We will use the standard credentials-based approach to access it, with an access key and secret key. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjy8H8T7Vb5M"
      },
      "source": [
        "cfg.S3_BUCKET_NAME='bitmovin-learning-lab-europe' #@param {type:\"string\"}\n",
        "cfg.S3_ACCESS_KEY='AKIATNF6LQRQUO5DMPFZ' #@param {type:\"string\"}\n",
        "cfg.S3_SECRET_KEY='' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQgzsUDJV-cb"
      },
      "source": [
        "### Something unique\n",
        "\n",
        "Finally, to prevent conflicts between your encodings and those of others who may be taking this tutorial at the same time, define a short string that would be unique to you yet easy to recognise. For example, your name (without spaces)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2NGKDHAWjDE"
      },
      "source": [
        "cfg.MY_ID=\"peterOct21\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY5GqnmCWo38"
      },
      "source": [
        "## Pre-flight check\n",
        "Let's quickly run some checks to make sure that your setup is ready to use. This is where those helpers come into play..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pgQPHSKWyUw"
      },
      "source": [
        "msg = helpers.validate_config()\n",
        "base_output_path = helpers.build_output_path()\n",
        "\n",
        "Markdown(\n",
        "    f\"<pre><font color='green'>{msg}.<br/>Your output files will be added to subdirectory <b>{base_output_path}</b></font></pre>\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEAZGqMKf7Nd"
      },
      "source": [
        "## Additional modules\n",
        "Finally, we import a number of standard Python modules that will be useful in our main code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMeAFEdggCbO"
      },
      "source": [
        "import collections\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHt9mlQyRwgx"
      },
      "source": [
        "## The Bitmovin SDK\n",
        "\n",
        "Finally, we need to import the Bitmovin SDK. In Python, this is typically done by using a package manager like `pip`, or using the `Setuptools`. More info can be found in the [Python SDK repository](https://github.com/bitmovin/bitmovin-api-sdk-python).\n",
        "In this interactive Colab environment, it's done in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF83acezSEbk"
      },
      "source": [
        "!pip install git+https://github.com/bitmovin/bitmovin-api-sdk-python.git@v1.86.0\n",
        "from bitmovin_api_sdk import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkFdOXUdfQj4"
      },
      "source": [
        "> ‚≠êÔ∏è &nbsp; The SDKs are updated very regularly, so make sure you have a process to migrate to the latest version on a regular basis. Our [release notes](https://bitmovin.com/docs/encoding/changelogs/rest) üìö &nbsp;will give you an indication of what to expect in terms of changes.\n",
        "\n",
        "> <font color=\"gray\">üóí &nbsp; It's usually not recommended in Python (or in most languages for that matter) to import all objets from a module as we've now done. It does however make it much simpler to experiment in this interactive way, so we will just ask forgiveness from the Python Gods and move on...</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "qI4_K7g8bwFF"
      },
      "source": [
        "# Configuring the Encoding\n",
        "Now that the boring bits are behind us, we are (finally) ready to start the real work and start configuring our very first encoding. \n",
        "\n",
        "First, we need to instantiate the Bitmovin API client, which is is used for all communication with the Bitmovin REST API. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "Ia50HGtDbwFS"
      },
      "source": [
        "api = BitmovinApi(api_key=cfg.API_KEY,\n",
        "                  tenant_org_id=cfg.ORG_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlUqJBMAtUfh"
      },
      "source": [
        "> <font color=\"gray\"> üí° &nbsp; If you want to see more detailed debug information when the SDK makes calls to the Bitmovin API, in particular the payloads sent and received by the API, add a parameter `logger=BitmovinApiLogger()` to this object</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "aOvDExJnbwFW"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step1.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "\n",
        "## Input and Output\n",
        "\n",
        "Every encoding needs at least one Input and Output. \n",
        "\n",
        "In the Bitmovin model, an Input holds the configuration to access a specific storage location with a specific protocol, from which files (or streams) will be downloaded. We support various types of input sources including HTTP(S), (S)FTP, Google Cloud Storage (GCS), Amazon Simple Storage Service (S3), Azure Blob Storage, and [others](https://bitmovin.com/docs/encoding/api-reference/sections/inputs) üìö . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "CN1mU4UIbwFY"
      },
      "source": [
        "input = HttpsInput(name=f'{cfg.MY_ID}_LearningLab_Sources',\n",
        "                   description='Web server for sample Learning Lab inputs',\n",
        "                   host=\"bitmovin-learning-lab-europe-inputs.s3.amazonaws.com\")\n",
        "input = api.encoding.inputs.https.create(https_input=input)\n",
        "print(\"Created input '{}' with id: {}\".format(input.name, input.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVLfJoJe_mp-"
      },
      "source": [
        "> üóí &nbsp; A couple of important notes:\n",
        "> \n",
        "> - Observe how we first create an object in the SDK, and then submit it to the API for creation of the resource. The API returns a full representation of the object, which now has an ID for it. We will use those identifiers to link the various objects that make up the full configuration.\n",
        "> \n",
        "> - Note also how we labeled the resource with a `name` and `description`. You can set those 2 fields on almost all Bitmovin resources you create. They can be useful to have human readable information returned, displayed in the dashboard, or to retrieve those resources by name with the APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVFAwMbllxJA"
      },
      "source": [
        "The same concepts apply to the Output, which defines where we will store the resulting files. Like Inputs, Outputs represent a set of information needed to access a specific storage. Here we will create a resource for an S3 bucket, but we also support a range of [other Outputs](https://bitmovin.com/docs/encoding/api-reference/sections/outputs) üìö ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9e_03we_iIu"
      },
      "source": [
        "output = S3Output(name=f'{cfg.MY_ID}_{cfg.S3_BUCKET_NAME}',\n",
        "                  description='Bucket for Learning Lab outputs',\n",
        "                  bucket_name=cfg.S3_BUCKET_NAME,\n",
        "                  access_key=cfg.S3_ACCESS_KEY,\n",
        "                  secret_key=cfg.S3_SECRET_KEY)\n",
        "output = api.encoding.outputs.s3.create(s3_output=output)\n",
        "print(\"Created output '{}' with id: {}\".format(output.name, output.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "8DuIDmyQbwFe"
      },
      "source": [
        "### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWE_SPoen6Ld"
      },
      "source": [
        "> ‚≠êÔ∏è &nbsp; **Reuse resources**\n",
        ">\n",
        "> Inputs and Outputs refer to storage locations, not to the files themselves. This makes them easily reusable across multiple encodings: create the Input and Output resources once, and reuse them for all the encodings that use the same storage locations. \n",
        "> \n",
        "> To do this, simply store the IDs of the resources when you've created them, and use them directly in the script. There are also GET APIs (and corresponding methods in the SDK) to retrieve details of the resources by their ID or by their name. \n",
        "> \n",
        "> For example, you could use \n",
        "> ```python\n",
        "> input = bitmovin_api.encoding.inputs.https.get(input_id='<INPUT_ID>')\n",
        "> output = bitmovin_api.encoding.outputs.s3.get(output_id='<OUTPUT_ID>')\n",
        "> ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E91Eh9YGxADW"
      },
      "source": [
        "\n",
        "> üí° &nbsp; **In the Dashboard**\n",
        ">\n",
        "> You can create Input and Output resources directly in the Dashboard: [Inputs](https://bitmovin.com/dashboard/encoding/inputs) and [Outputs](https://bitmovin.com/dashboard/encoding/outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "Q_dldXfbbwFr"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step2.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "## Configuring the codecs\n",
        "\n",
        "Next we are going to translate the rendition ladder requirements into a set of codec configurations. They define how the video or audio signal gets compressed and encoded into a stream that can be decoded by the player, with a specific codec.\n",
        "\n",
        "For simplicity, we use a helper tuple (a Python-esque construct) to capture this ladder (*some would call it a profile*), in terms of output height and bitrate. It's up to you how you define this in your own scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "gzXbDCHFbwFs"
      },
      "source": [
        "LadderRendition = collections.namedtuple('LadderRendition', 'height bitrate')\n",
        "video_renditions = [\n",
        "    LadderRendition(height=240,  bitrate=400_000),\n",
        "    LadderRendition(height=360,  bitrate=800_000),\n",
        "    LadderRendition(height=480,  bitrate=1_200_000),\n",
        "    LadderRendition(height=720,  bitrate=2_400_000),\n",
        "    LadderRendition(height=1080, bitrate=4_800_000),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "RZpJJB0kbwFw"
      },
      "source": [
        "### Video Config\n",
        "From it, we create a codec configuration for each of these renditions, for the H264/AVC codec most commonly supported by players today. We will use one of the Bitmovin [preset configurations](https://bitmovin.com/docs/encoding/tutorials/h264-presets) üìö , which are optimised configuration templates defined for most common use cases, whether your focus is on performance or quality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "9QaSJ2e0bwFy"
      },
      "source": [
        "video_configs = []\n",
        "for r in video_renditions:\n",
        "    video_config = H264VideoConfiguration(\n",
        "        name=f\"{cfg.MY_ID}_H264-{r.height}p@{r.bitrate}\",\n",
        "        height=r.height, \n",
        "        bitrate=r.bitrate, \n",
        "        preset_configuration=PresetConfiguration.VOD_STANDARD\n",
        "    )\n",
        "    video_config = api.encoding.configurations.video.h264.create(video_config)\n",
        "    video_configs.append(video_config)\n",
        "    print(\"Created video codec config '{}' with id: {}\".format(video_config.name, video_config.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "T006y4X1bwF6"
      },
      "source": [
        "### Audio Config\n",
        "We also need to create the audio configuration. A single AAC stream will do for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "sJCH8XmCbwF7"
      },
      "source": [
        "audio_config = AacAudioConfiguration(\n",
        "    name=f\"{cfg.MY_ID}_AAC-128k\",\n",
        "    bitrate=128_000, \n",
        "    rate=48_000)\n",
        "audio_config = api.encoding.configurations.audio.aac.create(aac_audio_configuration=audio_config)\n",
        "print(\"Created audio codec config '{}' with id: {}\".format(audio_config.name, audio_config.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "DwiNlFdavE8U"
      },
      "source": [
        "### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiKsXY_VvE8c"
      },
      "source": [
        "> ‚≠êÔ∏è &nbsp; **Reuse resources**\n",
        ">\n",
        "> Similarly to Inputs and Outputs, Configurations are not specific to a particular Encoding, and should be reused as much as possible. \n",
        "> \n",
        "> You can retrieve information about a configuration by calling the corresponding GET endpoints in the API, for example:\n",
        "> \n",
        "> ```python\n",
        "> codec_config = api.encoding.configurations.video.h264.get(configuration_id='<CONFIG_ID>')\n",
        "> ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ8v7LKwxO3i"
      },
      "source": [
        "> üí° &nbsp; **In the Dashboard**\n",
        ">\n",
        "> You can also create most Codec Configurations directly [in the Dashboard](https://bitmovin.com/dashboard/encoding/codec-configurations).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk2lBPc0xjHv"
      },
      "source": [
        "> üîé &nbsp; **What codec to use?**\n",
        ">\n",
        "> This will really be determined by what your players are able to decode. There are many video and audio codecs available, [supported in different ways](https://bitmovin.com/higher-quality-lower-bandwidth-multi-codec-streaming/) by different browsers and devices, some more efficient than others (and therefore generating smaller files and reducing streaming costs).\n",
        "> \n",
        "> - For video OTT streaming, the main ones are H264/AVC, H265/HEVC, VP9 and AV1.\n",
        "> - For audio, AAC, Dolby Digital (Plus), Opus and Vorbis are the most common ones.\n",
        "> \n",
        "> Our API documentation lists the [codecs we support](https://bitmovin.com/docs/encoding/api-reference/sections/configurations) üìö .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kif4n-VExk8v"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step3.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "## The Encoding\n",
        "\n",
        "An [Encoding](https://bitmovin.com/docs/encoding/api-reference/sections/encodings#/Encoding/PostEncodingEncodings) üìö &nbsp;is a collection of resources (inputs, outputs, codec configurations etc.), mapped to each other.\n",
        "\n",
        "It is really the central resource that represents the encoding task, the job you want to perform, and you will use its identifiers in pretty much every API call in the remainder of this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "KrRz_lEibwGA"
      },
      "source": [
        "encoding = Encoding(name=f\"{cfg.MY_ID} - basic encoding tutorial\",\n",
        "                    encoder_version=\"STABLE\",\n",
        "                    cloud_region=CloudRegion.AUTO)\n",
        "encoding = api.encoding.encodings.create(encoding=encoding)\n",
        "print(\"Created encoding '{}' with id: {}\".format(encoding.name, encoding.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duv8gDzTkKjP"
      },
      "source": [
        "### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQxHZwVtkNeN"
      },
      "source": [
        "> ‚≠êÔ∏è &nbsp; The `CloudRegion` defines through what cloud provider and in which region the encoding is performed. We are setting it to AUTO here (which is not necessary: it's the default value), to instruct the encoder to run it in the region closest to your input and output (if it can determine it). It's often best practice to use a specific region however, and you should ensure it is as close as possible to your storage, for best performance and to avoid egress costs.\n",
        " \n",
        "> ‚≠êÔ∏è &nbsp; The `EncoderVersion` is best to set to `STABLE` (again, the default value) for most workflows. You can also use `BETA` to use the very latest version, or a specific version number. For more, see our [recommendation on what version](https://bitmovin.com/docs/encoding/faqs/what-encoder-version-should-i-use) üìö &nbsp; to use. Our [release notes](https://bitmovin.com/docs/encoding/releases/encoder) üìö &nbsp;will inform you of what's new in each version.\n",
        "\n",
        "> ‚≠êÔ∏è &nbsp; You can also add one or more `labels` to your encoding. This can be useful to add metadata that could be used later down the line to [retrieve encodings](https://bitmovin.com/docs/encoding/tutorials/retrieving-vod-encoding-information-with-the-bitmovin-api#query-filters) üìö , or segment your [encoding statistics](https://bitmovin.com/docs/encoding/api-reference/sections/statistics#/Encoding/GetEncodingStatisticsLabelsLabels) üìö &nbsp;."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "IJHCBK8cbwGG"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_summary1.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "## Chaining the encoding\n",
        "\n",
        "So far we have created:\n",
        "* An Input\n",
        "* An Output\n",
        "* A set of codec Configurations\n",
        "* An empty Encoding object\n",
        "\n",
        "Having all these \"non-dependent\" resources ready, it is now time to connect the chain that will define the encoding job itself.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "7EwLTNPbbwFg"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step4.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "### Input Streams\n",
        "\n",
        "The first element in the chain is to let the encoder know how to obtain the input stream by specifying where the input file is located on the Input, and which stream(s) within it should be used as input in the encoding process.\n",
        "\n",
        "We define [IngestInputStreams](https://bitmovin.com/docs/encoding/api-reference/sections/encodings#/Encoding/PostEncodingEncodingsInputStreamsIngestByEncodingId) üìö &nbsp;resources for this purpose, with one for each input stream (video and audio in this case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "SGZB3N7nbwFh"
      },
      "source": [
        "input_file_path = \"cosmos_laundromat/cosmos_laundromat.mp4\"\n",
        "\n",
        "video_input_stream = IngestInputStream(input_id=input.id, \n",
        "                                       input_path=input_file_path, \n",
        "                                       selection_mode=StreamSelectionMode.VIDEO_RELATIVE,\n",
        "                                       position=0)\n",
        "video_input_stream = api.encoding.encodings.input_streams.ingest.create(encoding_id=encoding.id,\n",
        "                                                                        ingest_input_stream=video_input_stream)\n",
        "print(\"Created input stream with id: {}\".format(video_input_stream.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwTmZMf6BlzE"
      },
      "source": [
        "And the same for audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfiPkbfSBjUS"
      },
      "source": [
        "audio_input_stream = IngestInputStream(input_id=input.id,\n",
        "                                       input_path=input_file_path,\n",
        "                                       selection_mode=StreamSelectionMode.AUDIO_RELATIVE,\n",
        "                                       position=0)\n",
        "audio_input_stream = api.encoding.encodings.input_streams.ingest.create(encoding_id=encoding.id,\n",
        "                                                                        ingest_input_stream=audio_input_stream)\n",
        "print(\"Created input stream with id: {}\".format(audio_input_stream.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "566nb3rYg3a5"
      },
      "source": [
        "#### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "JYQcF_g_bwFl"
      },
      "source": [
        "> üí° &nbsp; The use of a relative `StreamSelectionMode` and `position=0` allows us to be somewhat explicit with regards to how the encoder should pick a media track from the input file. In simple unambiguous situations, you could use `StreamSelectionMode.AUTO` instead and no `position`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6ZzT5XGg3bC"
      },
      "source": [
        "> üîé &nbsp; The `IngestInputStream` is one of multiple types of InputStream resources. Others (single resources, or chains of resources) are used in more complex scenarios such as [audio channel manipulation](https://bitmovin.com/docs/encoding/tutorials/separating-and-combining-audio-streams) üìö , [trimming and concatenation](https://bitmovin.com/docs/encoding/tutorials/stitching-and-trimming-part-1-the-basics) üìö &nbsp;of input files, encoding with some high dynamic range (HDR) formats, or subtitle conversion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NfMpMHF_GJp"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step5.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "### Streams\n",
        "\n",
        "The next step is to create a series of output streams. These simply map one or multiple input streams to a single (elementary) output stream, and are the raw output of the encoding process itself.\n",
        "\n",
        "For our ABR use case, there is a simple one-to-one relationship between codecs and video streams. So, for each configuration created previously, we create a corresponding [Stream](https://bitmovin.com/docs/encoding/api-reference/sections/encodings#/Encoding/PostEncodingEncodingsStreamsByEncodingId) üìö &nbsp;, which we link to the IngestInputStream created earlier. We link the Stream to a Configuration, and attach it to our Encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "CbC2W9A7bwGI"
      },
      "source": [
        "video_streams = []\n",
        "for video_config in video_configs:\n",
        "    stream_shortname = '{}p_{}k'.format(video_config.height, round(video_config.bitrate/1000))\n",
        "    video_stream_input = StreamInput(input_stream_id=video_input_stream.id)\n",
        "    video_stream = Stream(name=f\"{cfg.MY_ID}_{stream_shortname}\",\n",
        "                          description=stream_shortname,\n",
        "                          codec_config_id=video_config.id,\n",
        "                          input_streams=[video_stream_input])\n",
        "    video_stream = api.encoding.encodings.streams.create(encoding_id=encoding.id, \n",
        "                                                         stream=video_stream)\n",
        "    video_streams.append(video_stream)\n",
        "    print(\"Created video stream '{}' with id: {}\".format(video_stream.name, video_stream.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UycRcrjeBsbx"
      },
      "source": [
        "The same applies to the single audio stream."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8sqQJlJBspH"
      },
      "source": [
        "audio_stream_input = StreamInput(input_stream_id=audio_input_stream.id)\n",
        "audio_stream = Stream(name=f'{cfg.MY_ID}_AAC',\n",
        "                      codec_config_id=audio_config.id, \n",
        "                      input_streams=[audio_stream_input])\n",
        "audio_stream = api.encoding.encodings.streams.create(encoding.id, stream=audio_stream)\n",
        "print(\"Created audio stream '{}' with id: {}\".format(audio_stream.name, audio_stream.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmhW67mgekFf"
      },
      "source": [
        "#### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgpI8oBnCp1d"
      },
      "source": [
        "> üí° &nbsp; The reason for the `input_streams` parameter taking an array of `StreamInput` objects is partly [for historical reasons](https://bitmovin.com/docs/encoding/faqs/what-is-the-difference-between-inputstreams-and-streaminput) üìö . StreamInputs are objects only used within the SDK. You do not create resources via the API for those; they are only used internally in the script, to model hierarchical API payloads. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecvkbgK4epqX"
      },
      "source": [
        "> üîé &nbsp; It is at the level of the Stream that many additional processing can be done, such as [deinterlacing](https://bitmovin.com/docs/encoding/tutorials/how-to-deinterlace-content-with-bitmovin-encoding) üìö &nbsp;the video, adding [Watermarks](https://bitmovin.com/docs/encoding/api-reference/sections/filters#/Encoding/PostEncodingFiltersEnhancedWatermark) üìö &nbsp;, generating [Thumbnails](https://bitmovin.com/docs/encoding/api-reference/sections/encodings#/Encoding/PostEncodingEncodingsStreamsThumbnailsByEncodingIdAndStreamId) üìö &nbsp;and [Sprites](https://bitmovin.com/docs/encoding/api-reference/sections/encodings#/Encoding/PostEncodingEncodingsStreamsSpritesByEncodingIdAndStreamId) üìö &nbsp;, or normalising the [audio volume](https://bitmovin.com/docs/encoding/api-reference/sections/filters#/Encoding/PostEncodingFiltersEbuR128SinglePass) üìö &nbsp;."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "zhh-YrldbwGS"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step6.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "### Muxings\n",
        "\n",
        "Raw output isn't enough however. An output stream must be muxed into a container, for example an MPEG Transport Stream (TS), or fragmented MPEG 4 boxes (ISOBMFF / FMP4). This process of containerizing is called muliplexing, or muxing in short. We therefore call the resource defining it a Muxing.\n",
        "\n",
        "For our use case, we will be using [FMP4 Muxings](https://bitmovin.com/docs/encoding/api-reference/sections/encodings#/Encoding/PostEncodingEncodingsMuxingsFmp4ByEncodingId) üìö ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "W_rG1d4QbwGT"
      },
      "source": [
        "video_muxings = []\n",
        "for video_stream in video_streams:\n",
        "    muxing_stream = MuxingStream(stream_id=video_stream.id)\n",
        "    muxing_output = EncodingOutput(output_id=output.id,\n",
        "                                   output_path='{}/video/{}'.format(base_output_path, video_stream.description),\n",
        "                                   acl=[AclEntry(permission=AclPermission.PUBLIC_READ)])\n",
        "    video_muxing = Fmp4Muxing(name=video_stream.name + \"_fmp4\",\n",
        "                              streams=[muxing_stream],\n",
        "                              segment_length=4.0,\n",
        "                              segment_naming=\"seg_%number%.m4s\",\n",
        "                              init_segment_name='init.mp4',\n",
        "                              outputs=[muxing_output])\n",
        "    video_muxing = api.encoding.encodings.muxings.fmp4.create(encoding_id=encoding.id, fmp4_muxing=video_muxing)\n",
        "    video_muxings.append(video_muxing)\n",
        "    print(\"Created video muxing '{}' with id: {}\".format(video_muxing.name, video_muxing.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "L1boUHUnbwGd"
      },
      "source": [
        "We also create an audio muxing, stored into a separate folder. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yEVXssZ1Erz"
      },
      "source": [
        "audio_muxing_stream = MuxingStream(stream_id=audio_stream.id)\n",
        "audio_muxing_output = EncodingOutput(output_id=output.id,\n",
        "                                     output_path=base_output_path+'/audio/',\n",
        "                                     acl=[AclEntry(scope='*', permission=AclPermission.PUBLIC_READ)])\n",
        "audio_muxing = Fmp4Muxing(name=f\"{audio_stream.name}_fmp4\",\n",
        "                          streams=[audio_muxing_stream],\n",
        "                          segment_length=4.0,\n",
        "                          segment_naming=\"seg_%number%.m4s\",\n",
        "                          init_segment_name='init.mp4',\n",
        "                          outputs=[audio_muxing_output])\n",
        "audio_muxing = api.encoding.encodings.muxings.fmp4.create(encoding_id=encoding.id, fmp4_muxing=audio_muxing)\n",
        "print(\"Created audio muxing '{}' with id: {}\".format(audio_muxing.name, audio_muxing.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "pHgbv5iWGVH6"
      },
      "source": [
        "#### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P-8zNQE_e-O"
      },
      "source": [
        "> üóí &nbsp; There are a few things to note about this code. A number of additional objects are used to define some aspects of the Muxing:\n",
        ">  - The `MuxingStream` maps the `Stream` to the `Muxing`. The Muxing accepts an array of those, in order to allow muxing of multiple streams into a single container, for example audio and video streams together. For this tutorial's use case, standard modern ABR practice is to have a single stream per muxing. \n",
        ">  - The `EncodingOutput` defines where the muxing gets written in the Output storage, and (if applicable) what permissions will be applied to it. We make them readably publically here to make it easy to do a playback test later on.\n",
        ">\n",
        "> Just as with the `StreamInput` object in the previous section, note that these 2 objects are only used within the SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru_V63MpGVH6"
      },
      "source": [
        "> üîé &nbsp; What muxing to use?\n",
        "> In many ways the decision here, just like with codecs, mainly depends on what your players and devices are able to support.  Not all muxings support all codecs.\n",
        "> \n",
        "> In the case of ABR streaming, it also partly depends on the type of manifest that you will provide to the player (more on this below). Usually, for MPEG-DASH, FMP4 muxings are used, and TS muxings for HLS, although modern devices should be able to support FMP4 in HLS as well (which is what this tutorial outputs, for simplicity)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "x9FiZEwhbwGm"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step7.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "## Combining into a manifest\n",
        "We will ask the encoder to generate manifests as well. A manifest is used by ABR clients to find all of the quality levels, audio tracks, etc. that are available for streaming. \n",
        "\n",
        "We are going to generate two:\n",
        "- An _MPEG-DASH_ (Dynamic Adaptive Streaming over HTTP) manifest, typically used to play on most browsers and Android devices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "ODmU9M8ubwGo"
      },
      "source": [
        "manifest_output = EncodingOutput(output_id=output.id,\n",
        "                                 output_path=base_output_path+'/',\n",
        "                                 acl=[AclEntry(scope='*', permission=AclPermission.PUBLIC_READ)])\n",
        "dash_manifest = DashManifestDefault(\n",
        "    name=f\"{cfg.MY_ID}_DashManifest\",\n",
        "    manifest_name=\"stream.mpd\",\n",
        "    encoding_id=encoding.id,\n",
        "    version=DashManifestDefaultVersion.V2,\n",
        "    outputs=[manifest_output])\n",
        "dash_manifest = api.encoding.manifests.dash.default.create(dash_manifest)\n",
        "print(\"Created DASH manifest '{}' with id: {}\".format(dash_manifest.name, dash_manifest.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP2Lw8OVJdfV"
      },
      "source": [
        "- An _HLS_ (HTTP Live Streaming) manifest, typically used on iOS devices and Safari browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc4mM-ARJiK5"
      },
      "source": [
        "hls_manifest = HlsManifestDefault(\n",
        "    name=f\"{cfg.MY_ID}_HlsManifest\",\n",
        "    manifest_name=\"stream.m3u8\",\n",
        "    encoding_id=encoding.id,\n",
        "    version=HlsManifestDefaultVersion.V1,\n",
        "    outputs=[manifest_output])\n",
        "hls_manifest = api.encoding.manifests.hls.default.create(hls_manifest)\n",
        "print(\"Created HLS manifest '{}' with id: {}\".format(hls_manifest.name, hls_manifest.id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kkF7JoaS_P2"
      },
      "source": [
        "### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIswIXPeTOeh"
      },
      "source": [
        "> üîé &nbsp; Our code uses [Default Manifests](https://bitmovin.com/docs/encoding/tutorials/how-to-create-manifests-for-your-encodings) üìö &nbsp;, a construct that instructs the encoder to determine how to best generate the manifest based on what resources have been created by the encoding. This simplifies the code greatly for simple scenarios like the one in this tutorial. \n",
        ">\n",
        "> If you need more control, or in more complex scenarios, you will want to generate Custom Manifests, by defining exactly what the content of the manifest should be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "XKj5Qq1ObwGg"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step8.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "## Starting the encoding...\n",
        "\n",
        "We are done with the configuration. Until now, no actual encoding process has taken place; all that has happened is that resources have been created in the Bitmovin platform, ready to be used by the encoder to retrieve its instructions.\n",
        "\n",
        "It is now time to [start the encoding](https://bitmovin.com/docs/encoding/api-reference/sections/encodings#/Encoding/PostEncodingEncodingsStartByEncodingId) üìö ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "FkiX8-1abwGi"
      },
      "source": [
        "start_request = StartEncodingRequest(\n",
        "    vod_dash_manifests=[ManifestResource(manifest_id=dash_manifest.id)],\n",
        "    vod_hls_manifests=[ManifestResource(manifest_id=hls_manifest.id)]\n",
        ")\n",
        "\n",
        "api.encoding.encodings.start(encoding_id=encoding.id,\n",
        "                             start_encoding_request=start_request)\n",
        "print(\"Starting encoding\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2_Rml-OoC16"
      },
      "source": [
        "### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agiGIISSUV23"
      },
      "source": [
        "> üóí The `StartEncodingRequest` object is used to provide additional instructions to the encoder, in this case what manifests to generate together with the encoding. It is worth noting that Manifests can be created and generated after the encoding is finished, with their own `start` calls, as described [here](https://bitmovin.com/docs/encoding/tutorials/how-to-create-manifests-for-your-encodings) üìö ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSJ5z8fsArjZ"
      },
      "source": [
        "###... and monitoring it\n",
        "\n",
        "At this stage, you should be able to go to the dashboard to see your encoding and track its progress. The following code will generate the Dashboard URL to get you directly to the correct page."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL1KsuT-Z44F"
      },
      "source": [
        "url = helpers.build_dashboard_url(encoding.id)\n",
        "Markdown(\n",
        "    f\"<font color='green'>You can now check encoding progress in the dashboard at <a href='{url}' target='_new'>{url}</a>.</font>\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXfVWHTCZlE1"
      },
      "source": [
        "<img src=\"http://demo.bitmovin.com/public/learning-labs/encoding/OM_mini_partial_step9.png\" align=\"right\" width=\"320px\">\n",
        "\n",
        "You can also programmatically monitor the encoding in your script by calling (or \"polling\") its [Status endpoint](https://bitmovin.com/docs/encoding/api-reference/sections/encodings#/Encoding/GetEncodingEncodingsStatusByEncodingId) üìö &nbsp;on a regular basis. This is the easiest way to keep track of the encoding when you are testing your encoding configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGno_QyOPs-X"
      },
      "source": [
        "while True:\n",
        "    task = api.encoding.encodings.status(encoding.id)\n",
        "    print(\"Got task status {} - {}%\".format(task.status, task.progress))\n",
        "    if task.status == Status.ERROR:\n",
        "        print(\"Error during encoding!\")\n",
        "        raise SystemExit\n",
        "    if task.status == Status.FINISHED:\n",
        "        print(\"Encoding complete\")\n",
        "        break\n",
        "    time.sleep(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE28ufzGoj8Z"
      },
      "source": [
        "### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glHZdqoxVFJO"
      },
      "source": [
        "> üóí &nbsp; If an error occurs with the encoding, you can find information about the error either by going to the Dashboard, or by looking at the Task payload returned by the Status endpoint, which contains details about the encoding process.\n",
        "\n",
        "\n",
        "> ‚≠êÔ∏è &nbsp; Polling is useful for experimentation. However, for production environments with automated workflows, you should use [webhooks](https://https://bitmovin.com/docs/encoding/api-reference/sections/notifications-webhooks) üìö &nbsp;instead to receive programmatic notifications when the encoding succeeds or fails.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn1wYl-QNCsk"
      },
      "source": [
        "# Playback test\n",
        "You can now try playing back the stream, by using the manifest URLs in our [Bitmovin Stream Test player](https://bitmovin.com/demos/stream-test). Manifest URLs are predictable (since you've defined where the manifest files should be stored and with what names), so we can easily determine what they are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ0xoaSoVy5-"
      },
      "source": [
        "dash_manifest_url = \"https://\"+cfg.S3_BUCKET_NAME+\".s3.amazonaws.com/\" + manifest_output.output_path + dash_manifest.manifest_name\n",
        "hls_manifest_url = \"https://\"+cfg.S3_BUCKET_NAME+\".s3.amazonaws.com/\" + manifest_output.output_path + hls_manifest.manifest_name\n",
        "display( Markdown(f\"DASH Manifest URL: {dash_manifest_url}\"))\n",
        "display( Markdown(f\"HLS Manifest URL: {hls_manifest_url}\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhKZhLfBSLav"
      },
      "source": [
        "## In your own player\n",
        "Alternatively, you can just play it right here with a little embedded player. \n",
        "\n",
        "To retrieve your player license, head to the Dashboard's [player license page](https://bitmovin.com/dashboard/player/licenses)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wcKaY6OSea6"
      },
      "source": [
        "cfg.PLAYER_LICENSE='f9e2cf25-9cdd-4c9d-a314-90fdb6d5590c' #@param {type:\"string\"}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7TDrikdS6qF"
      },
      "source": [
        "embed_url = \"https://demo.bitmovin.com/public/learning-labs/encoding/test-players/basic-dash-player.html?\"\n",
        "embed_url += \"license=\"+cfg.PLAYER_LICENSE\n",
        "embed_url += \"&mpdurl=\"+dash_manifest_url\n",
        "embed_url += \"&hlsurl=\"+hls_manifest_url\n",
        "\n",
        "IFrame(src=embed_url, width=800, height=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9sPhvxcoqTn"
      },
      "source": [
        "### *Notes*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1rt_3ALotHq"
      },
      "source": [
        "> üóí &nbsp; You may have to allowlist the \"google.com\" domain for your player license first. See [the documentation](https://bitmovin.com/docs/player/faqs/how-can-i-allowlist-a-domain) üìö &nbsp;for details.</font>"
      ]
    }
  ]
}